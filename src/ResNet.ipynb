{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import sklearn.model_selection as model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set\n",
    "dataset = []\n",
    "with open('nparr_spec_image.pickle','rb') as modelFile:\n",
    "     dataset = pickle.load(modelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 722)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[166 176 176 ... 241 241 241]\n",
      " [165 175 175 ... 255 255 255]\n",
      " [165 175 175 ... 255 255 255]\n",
      " ...\n",
      " [238 252 252 ... 255 255 255]\n",
      " [237 251 251 ... 255 255 255]\n",
      " [237 251 251 ... 255 255 255]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matrix(dataset[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ResNet model with initial weights\n",
    "tf_model = models.resnet18(weights = models.ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(tf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify initial and last layers to allow model to adapt to our inputs/outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_modules of ResNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 3, kernel_size=(9, 9), stride=(4, 4), padding=(3, 3))\n",
      "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  )\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# Get last layer and reset last linear layer\n",
    "last_name, last_layer = list(tf_model.named_modules())[-1]\n",
    "tf_model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "# Prepend initial layers\n",
    "tf_model.conv1 = nn.Sequential(\n",
    "    nn.Conv2d(1, 3, kernel_size= (9,9), stride=(4,4), padding=(3,3)),\n",
    "    nn.BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    tf_model.conv1\n",
    ")\n",
    "print(tf_model.named_modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['bird', 'cat', 'chicken', 'cow', 'dog', 'donkey', 'frog', 'lion', 'monkey', 'sheep']\n",
    "import operator\n",
    "batch_size = 4\n",
    "\n",
    "# Used from Google Gemini\n",
    "from torch.utils.data import Dataset\n",
    "class DAN_Dataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = torch.tensor(data)\n",
    "        self.labels = torch.tensor(labels)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "def fetch_dataloader(data, batch_size, train_transform=None, val_transform=None):\n",
    "    '''\n",
    "    Inputs:\n",
    "    :param data: Data to load into DataLoaders.\n",
    "    :param batch_size: Batch size for DataLoaders.\n",
    "    :param train_transform: Transforms to apply to train Dataset\n",
    "    :param val_transform: Transforms to apply to validation Dataset\n",
    "    '''\n",
    "    # https://www.geeksforgeeks.org/python-get-first-element-in-list-of-tuples/\n",
    "    images = list(map(operator.itemgetter(0), dataset))\n",
    "    images = np.array(images).astype(np.float32)\n",
    "    # Grab lowercase labels and convert to integers\n",
    "    labels = list(map(operator.itemgetter(1), dataset))\n",
    "    labels = list(map(lambda x: x.lower(), labels))\n",
    "    labels = list(map(lambda x: classes.index(x), labels))\n",
    "\n",
    "    # Split into train and validation sets.\n",
    "    x_train, x_val, y_train, y_val  = model_selection.train_test_split(images, labels, train_size=0.8, shuffle=True)\n",
    "    # Convert to Dataset\n",
    "    train_data = DAN_Dataset(x_train, y_train, train_transform)\n",
    "    val_data = DAN_Dataset(x_val, y_val, val_transform)\n",
    "\n",
    "    # Separate every 10th value\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), \n",
    "     transforms.ConvertImageDtype(torch.float32),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.ConvertImageDtype(torch.float32),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = fetch_dataloader(dataset, batch_size, train_transform, val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tf_model.to(device)\n",
    "tf_model.train()\n",
    "\n",
    "# Set the loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(tf_model.parameters(), lr=0.001, momentum=0.9)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = torch.reshape(inputs, (4, 1, 303, 722))\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = tf_model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini generated code with google search: \"pytorch evaluate accuracy of model\"\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "def evaluate_model(model, data_val, classes, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    accuracy = Accuracy(task='multiclass', num_classes=classes).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(data_val, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            try:\n",
    "                inputs, labels = data\n",
    "                inputs = torch.reshape(inputs, (inputs.shape[0], 1, 303, 722))\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                predictions.append(outputs)\n",
    "                accuracy.update(outputs, labels)\n",
    "            except:\n",
    "                continue\n",
    "        return accuracy.compute(), predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  tensor(0.9771, device='cuda:0')\n",
      "[4, 1, 0, 7, 0, 1, 4, 1, 1, 0, 4, 1, 0, 1, 9, 0, 1, 1, 4, 3, 1, 3, 9, 4, 1, 6, 0, 4, 2, 0, 6, 1, 1, 2, 3, 0, 2, 4, 0, 6, 8, 4, 6, 0, 7, 9, 3, 9, 4, 4, 1, 4, 7, 7, 9, 0, 4, 1, 4, 4, 1, 3, 1, 1, 0, 6, 3, 1, 6, 1, 1, 6, 1, 9, 1, 1, 0, 4, 0, 4, 0, 0, 6, 4, 4, 1, 0, 0, 1, 9, 4, 4, 4, 1, 9, 4, 7, 4, 5, 0, 1, 1, 0, 4, 8, 0, 0, 3, 3, 0, 1, 1, 4, 7, 0, 4, 1, 0, 4, 3, 3, 1, 0, 2, 7, 4, 8, 1, 3, 1, 1, 0, 0, 3, 1, 0, 1, 0, 0, 2, 0, 0, 2, 8, 6, 1, 9, 7, 2, 0, 0, 1, 0, 8, 1, 1, 9, 0, 3, 3, 0, 4, 4, 4, 0, 4, 3, 1, 7, 3, 0, 4, 4, 4, 0]\n",
      "['bird', 'cat', 'chicken', 'cow', 'dog', 'donkey', 'frog', 'lion', 'monkey', 'sheep']\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "accuracy, predictions = evaluate_model(tf_model, val, 10, device)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "pred_labels = []\n",
    "for batch in predictions:\n",
    "    for prediction in batch:\n",
    "        x = (prediction == torch.max(prediction)).nonzero(as_tuple=False)[0]\n",
    "        pred_labels.append(x)\n",
    "pred_labels = list(map(lambda x: x.cpu().numpy().item(), pred_labels))\n",
    "print(pred_labels)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 3, 76, 180]             246\n",
      "       BatchNorm2d-2           [-1, 3, 76, 180]               6\n",
      "              ReLU-3           [-1, 3, 76, 180]               0\n",
      "            Conv2d-4           [-1, 64, 38, 90]           9,408\n",
      "       BatchNorm2d-5           [-1, 64, 38, 90]             128\n",
      "              ReLU-6           [-1, 64, 38, 90]               0\n",
      "         MaxPool2d-7           [-1, 64, 19, 45]               0\n",
      "            Conv2d-8           [-1, 64, 19, 45]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 19, 45]             128\n",
      "             ReLU-10           [-1, 64, 19, 45]               0\n",
      "           Conv2d-11           [-1, 64, 19, 45]          36,864\n",
      "      BatchNorm2d-12           [-1, 64, 19, 45]             128\n",
      "             ReLU-13           [-1, 64, 19, 45]               0\n",
      "       BasicBlock-14           [-1, 64, 19, 45]               0\n",
      "           Conv2d-15           [-1, 64, 19, 45]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 19, 45]             128\n",
      "             ReLU-17           [-1, 64, 19, 45]               0\n",
      "           Conv2d-18           [-1, 64, 19, 45]          36,864\n",
      "      BatchNorm2d-19           [-1, 64, 19, 45]             128\n",
      "             ReLU-20           [-1, 64, 19, 45]               0\n",
      "       BasicBlock-21           [-1, 64, 19, 45]               0\n",
      "           Conv2d-22          [-1, 128, 10, 23]          73,728\n",
      "      BatchNorm2d-23          [-1, 128, 10, 23]             256\n",
      "             ReLU-24          [-1, 128, 10, 23]               0\n",
      "           Conv2d-25          [-1, 128, 10, 23]         147,456\n",
      "      BatchNorm2d-26          [-1, 128, 10, 23]             256\n",
      "           Conv2d-27          [-1, 128, 10, 23]           8,192\n",
      "      BatchNorm2d-28          [-1, 128, 10, 23]             256\n",
      "             ReLU-29          [-1, 128, 10, 23]               0\n",
      "       BasicBlock-30          [-1, 128, 10, 23]               0\n",
      "           Conv2d-31          [-1, 128, 10, 23]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 10, 23]             256\n",
      "             ReLU-33          [-1, 128, 10, 23]               0\n",
      "           Conv2d-34          [-1, 128, 10, 23]         147,456\n",
      "      BatchNorm2d-35          [-1, 128, 10, 23]             256\n",
      "             ReLU-36          [-1, 128, 10, 23]               0\n",
      "       BasicBlock-37          [-1, 128, 10, 23]               0\n",
      "           Conv2d-38           [-1, 256, 5, 12]         294,912\n",
      "      BatchNorm2d-39           [-1, 256, 5, 12]             512\n",
      "             ReLU-40           [-1, 256, 5, 12]               0\n",
      "           Conv2d-41           [-1, 256, 5, 12]         589,824\n",
      "      BatchNorm2d-42           [-1, 256, 5, 12]             512\n",
      "           Conv2d-43           [-1, 256, 5, 12]          32,768\n",
      "      BatchNorm2d-44           [-1, 256, 5, 12]             512\n",
      "             ReLU-45           [-1, 256, 5, 12]               0\n",
      "       BasicBlock-46           [-1, 256, 5, 12]               0\n",
      "           Conv2d-47           [-1, 256, 5, 12]         589,824\n",
      "      BatchNorm2d-48           [-1, 256, 5, 12]             512\n",
      "             ReLU-49           [-1, 256, 5, 12]               0\n",
      "           Conv2d-50           [-1, 256, 5, 12]         589,824\n",
      "      BatchNorm2d-51           [-1, 256, 5, 12]             512\n",
      "             ReLU-52           [-1, 256, 5, 12]               0\n",
      "       BasicBlock-53           [-1, 256, 5, 12]               0\n",
      "           Conv2d-54            [-1, 512, 3, 6]       1,179,648\n",
      "      BatchNorm2d-55            [-1, 512, 3, 6]           1,024\n",
      "             ReLU-56            [-1, 512, 3, 6]               0\n",
      "           Conv2d-57            [-1, 512, 3, 6]       2,359,296\n",
      "      BatchNorm2d-58            [-1, 512, 3, 6]           1,024\n",
      "           Conv2d-59            [-1, 512, 3, 6]         131,072\n",
      "      BatchNorm2d-60            [-1, 512, 3, 6]           1,024\n",
      "             ReLU-61            [-1, 512, 3, 6]               0\n",
      "       BasicBlock-62            [-1, 512, 3, 6]               0\n",
      "           Conv2d-63            [-1, 512, 3, 6]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 3, 6]           1,024\n",
      "             ReLU-65            [-1, 512, 3, 6]               0\n",
      "           Conv2d-66            [-1, 512, 3, 6]       2,359,296\n",
      "      BatchNorm2d-67            [-1, 512, 3, 6]           1,024\n",
      "             ReLU-68            [-1, 512, 3, 6]               0\n",
      "       BasicBlock-69            [-1, 512, 3, 6]               0\n",
      "AdaptiveAvgPool2d-70            [-1, 512, 1, 1]               0\n",
      "           Linear-71                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,181,894\n",
      "Trainable params: 11,181,894\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.83\n",
      "Forward/backward pass size (MB): 18.81\n",
      "Params size (MB): 42.66\n",
      "Estimated Total Size (MB): 62.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(tf_model, (1, 303, 722))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
